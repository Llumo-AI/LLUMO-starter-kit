{"cells":[{"cell_type":"markdown","metadata":{"id":"HJf2c7E7KMVT"},"source":["##Setting up the environment\n","###Importing libraries:\n","\n","* os: This module provides a way to use operating system dependent functionality, like reading environment variables.\n","* OpenAI: This is the official OpenAI Python client, used to interact with OpenAI's API.\n","* requests: A popular library for making HTTP requests in Python.\n","* json: Used for parsing JSON data, which is common in API responses.\n","* logging: Provides a flexible framework for generating log messages in Python.\n","* getpass: Allows secure password prompts where the input is not displayed on the screen.\n","\n","\n","###Setting up logging:\n","\n","* We use `logging.basicConfig()` to configure the logging system. The `level=logging.INFO` argument sets the threshold for logging messages to INFO level and above.\n","* We create a logger object named logger that we'll use throughout our script to log important information and errors.\n","\n","\n","\n","This setup ensures we have all necessary tools to interact with APIs, handle data, and track any issues that might occur during execution."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9032,"status":"ok","timestamp":1725534907448,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"JI7kRgEWNSc-","outputId":"eb48ef8c-3b4e-4674-bf41-e18d835e1099"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.43.0\n","Libraries imported and logging set up successfully.\n"]}],"source":["!pip install openai\n","import os\n","from openai import OpenAI\n","import requests\n","import json\n","import logging\n","from getpass import getpass\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"Libraries imported and logging set up successfully.\")"]},{"cell_type":"markdown","metadata":{"id":"XNoUu5e8K4-u"},"source":["##Secure API key handling\n","###Secure API key input:\n","\n","* We use `getpass()` to prompt the user for their API keys. This function hides the input, making it more secure than using regular input().\n","* This approach is safer than hardcoding API keys in your script, which could accidentally be shared or exposed.\n","\n","\n","###Setting environment variables:\n","\n","* We use `os.environ` to set environment variables for both API keys.\n","* Environment variables are a secure way to store sensitive information, as they're not part of your code and are only accessible within the current process.\n","\n","\n","###Initializing the OpenAI client:\n","\n","* We create an instance of the OpenAI client using the API key we just set.\n","* Using `os.getenv(\"OPENAI_API_KEY\")` retrieves the API key from the environment variables.\n","\n","\n","\n","This method ensures that your API keys are handled securely and are readily available for use in your script."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zO7mU9nHLstm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725534934911,"user_tz":-330,"elapsed":27484,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"}},"outputId":"05a599d9-f48e-45bd-8a1b-f1ef45833a34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your OpenAI API key: ··········\n","Enter your Llumo API key: ··········\n","API keys securely set and OpenAI client initialized.\n"]}],"source":["# Cell 2: Secure API key handling\n","\n","# Securely input API keys\n","openai_api_key = getpass(\"Enter your OpenAI API key: \")\n","llumo_api_key = getpass(\"Enter your Llumo API key: \")\n","\n","# Set environment variables\n","os.environ['OPENAI_API_KEY'] = openai_api_key\n","os.environ['LLUMO_API_KEY'] = llumo_api_key\n","\n","# Initialize OpenAI client\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n","\n","print(\"API keys securely set and OpenAI client initialized.\")"]},{"cell_type":"markdown","metadata":{"id":"PfSNDHSVLv6q"},"source":["##Define Llumo compression function\n","###Function definition:\n","\n","* We define a function `compress_with_llumo` that takes a text input and an optional topic.\n","\n","\n","###API setup:\n","\n","* We retrieve the Llumo API key from environment variables.\n","* We set the API endpoint and prepare headers for the HTTP request.\n","\n","\n","###Payload preparation:\n","\n","* We create a payload dictionary with the input text.\n","* If a topic is provided, we add it to the payload.\n","\n","\n","###API request:\n","\n","* We use `requests.post()` to send a POST request to the Llumo API.\n","`response.raise_for_status()` will raise an exception for HTTP errors.\n","\n","\n","###Response parsing:\n","\n","* We parse the JSON response and extract the compressed text and token counts.\n","* We calculate the compression percentage.\n","\n","\n","###Error handling:\n","\n","* We use a try-except block to catch potential errors:\n","\n"," * JSON decoding errors\n"," * Request exceptions\n"," * Unexpected response structure\n","\n","\n","* If an error occurs, we log it and return the original text with failure indicators.\n","\n","\n","### Return values:\n","\n","* The function returns a tuple containing:\n","\n"," * Compressed text (or original if compression failed)\n"," * Success boolean\n"," * Compression percentage\n"," * Initial token count\n"," * Final token count\n","\n","\n","\n","\n","\n","This function encapsulates the entire process of interacting with the Llumo API for text compression, including error handling and result processing."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1725534934911,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"tCoNUERsLuRS"},"outputs":[],"source":["def compress_with_llumo(text):\n","    # Retrieve the Llumo API key from environment variables\n","    LLUMO_API_KEY = os.getenv('LLUMO_API_KEY')\n","\n","    # Define the Llumo API endpoint for text compression\n","    LLUMO_ENDPOINT = \"https://app.llumo.ai/api/compress\"\n","\n","    # Set the headers for the API request\n","    headers = {\n","        \"Content-Type\": \"application/json\",  # Specify the content type as JSON\n","        \"Authorization\": f\"Bearer {LLUMO_API_KEY}\"  # Authorization header with the API key\n","    }\n","\n","    # Create the payload for the API request with the provided text\n","    payload = {\"prompt\": text}\n","\n","    try:\n","        # Make a POST request to the Llumo API with the payload and headers\n","        response = requests.post(LLUMO_ENDPOINT, json=payload, headers=headers)\n","        response.raise_for_status()\n","\n","        # Parse the JSON response from the API\n","        result = response.json()\n","        data = json.loads(result['data']['data'])\n","\n","        # Extract compressed text and token information\n","        compressed_text = data.get('compressedPrompt', text)\n","        initial_tokens = data.get('initialTokens', 0)\n","        final_tokens = data.get('finalTokens', 0)\n","\n","        # Calculate the compression percentage\n","        compression_percentage = ((initial_tokens - final_tokens) / initial_tokens) * 100 if initial_tokens else 0\n","\n","        # Return the compressed text, success flag, compression percentage, and token counts\n","        return compressed_text, True, compression_percentage, initial_tokens, final_tokens\n","    except Exception as e:\n","        print(f\"Error compressing text: {str(e)}\")\n","        return text, False, 0, 0, 0\n"]},{"cell_type":"markdown","metadata":{"id":"o59T0PevM8no"},"source":["##Define example prompt and test without compression\n","###Defining the prompt:\n","\n","* We create a detailed prompt about photosynthesis. This serves as our example text for compression.\n","\n","\n","###Testing without compression:\n","\n","* We use the OpenAI client to send a request to the GPT-3.5-turbo model.\n","* The messages parameter follows the chat format:\n","\n"," * A system message sets the AI's role.\n"," * A user message contains our prompt.\n","\n","\n","\n","\n","###Displaying results:\n","\n","* We print the AI's response to the prompt.\n","* We also print the total number of tokens used, which is important for understanding API usage and costs.\n","\n","This cell demonstrates how the API would typically be used without any compression, providing a baseline for comparison.\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9055,"status":"ok","timestamp":1725535397126,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"nv0xHxrSNyKl","outputId":"2af0698d-98c5-4ec2-c87b-c73d468bfee7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Without Llumo Compression:\n","**Interview Question:**\n","---\n","**Part 1: Basic Implementation**\n","\n","You are given the task of implementing basic operations for a Binary Search Tree (BST) in Python. Your implementation should include methods for insertion, deletion, and search on the BST. \n","\n","Please write Python code for the following:\n","1. Implement a BST class with the necessary methods for insertion, deletion, and search.\n","2. Ensure that your implementation handles cases of duplicate values appropriately.\n","3. Write a simple test script to demonstrate the functionality of your BST class with a sample insertion, deletion, and search operations.\n","\n","Please provide detailed comments in your code to explain your thought process and choices made during implementation.\n","\n","---\n","\n","**Part 2: Optimization Challenge**\n","\n","Once you have completed the basic implementation, let's focus on optimization. Discuss a scenario where the BST may become unbalanced, significantly impacting the efficiency of search operations. Please propose and implement a solution to optimize your BST to handle this situation efficiently. You can consider implementing a self-balancing tree such as AVL tree or Red-Black tree.\n","\n","Include this optimization in your existing BST class, ensuring that the BST remains self-balancing under various insertion and deletion operations. \n","\n","Describe the trade-offs involved in using a self-balancing tree and the impact this optimization has on the time complexity of key operations.\n","\n","---\n","\n","**Part 3: Edge Cases and Analysis**\n","\n","Identify and address specific edge cases that your implementation should handle, including:\n","1. Empty trees\n","2. Duplicate values\n","3. Highly unbalanced trees\n","\n","Explain how your implementation tackles each of these edge cases and how it affects the overall performance and correctness of the BST operations.\n","\n","---\n","\n","**Part 4: Complexity Discussion**\n","\n","Analyze the time and space complexity of your BST implementation. Provide a comprehensive explanation of the best-case, average-case, and worst-case time complexity for insertion, deletion, and search operations in your BST. Discuss how the time and space complexity vary under different scenarios, particularly in balanced versus unbalanced trees.\n","\n","---\n","\n","**Detailed Solution Expectations:**\n","\n","1. **Step-by-Step Implementation:** Provide clean and efficient Python code with detailed comments explaining each part of the implementation.\n","2. **Explanatory Commentary:** Justify your choices, data structures used, algorithm logic, and any optimizations applied.\n","3. **Complexity Justification:** Analyze time and space complexity using Big-O notation for each operation.\n","4. **Edge Case Handling:** Demonstrate how edge cases are handled and adjusted in your code.\n","5. **Optimizations and Alternatives:** Discuss alternative approaches and optimizations, particularly related to self-balancing trees.\n","\n","---\n","**Evaluation and Scoring:**\n","\n","1. **Correctness:** Assess the correctness of your implementation and handling of edge cases.\n","2. **Efficiency:** Evaluate the efficiency of your solution in terms of time and space complexity.\n","3. **Clarity and Communication:** Evaluate how effectively you communicate your thought process and choices.\n","4. **Problem-Solving Skills:** Assess your approach to problem-solving, adaptability to challenges, and performance under time constraints.\n","\n","---\n","This question is designed to test your proficiency in understanding Binary Search Trees, implementing essential operations, optimizing for efficiency, handling edge cases, and analyzing complexity. Your ability to write clean, efficient code with detailed explanations will be critical in demonstrating your skills in this area. Best of luck!\n","Tokens used: 2078\n","\n"]}],"source":["# Cell 4: Define example prompt and test without compression\n","\n","# Example prompt\n","topic = \"Binary Search Trees (BST)\"\n","field = \"Data Structures and Algorithms (DSA)\"\n","difficulty_level = \"mid-level\"\n","experience_range = \"2-4 years\"\n","time_limit = \"45-60 minute\"\n","key_operations = \"insertion, deletion, search, and traversal\"\n","algorithm_focus = \"search and traversal algorithms\"\n","advanced_concept = \"self-balancing trees\"\n","core_operations = \"insertion, deletion, and search\"\n","complexity_analysis = \"time and space complexity\"\n","notation = \"Big-O notation\"\n","scenario_types = \"best-case, average-case, and worst-case\"\n","edge_cases = \"empty trees, duplicate values, and highly unbalanced trees\"\n","optimization_technique = \"implementing a self-balancing tree\"\n","specific_edge_cases = \"empty trees or duplicate values\"\n","programming_language = \"Python\"\n","advanced_operation = \"maintaining subtree sizes for order statistics\"\n","comparison_structure_1 = \"heaps\"\n","comparison_structure_2 = \"hash tables\"\n","\n","prompt = f\"\"\"\n","Create an advanced and highly detailed interview question centered on {topic}, a fundamental concept in {field}. The objective of this question is to thoroughly evaluate the candidate's skills in implementing, optimizing, and analyzing algorithms related to {topic}. This question should be suitable for a {difficulty_level} software engineer with {experience_range} of industry experience. The question should be challenging yet solvable within a {time_limit} interview. Below are the specific requirements and guidelines that should be followed:\n","\n","Core Focus Areas:\n","Data Structure: The question must revolve around {topic}. It should test the candidate's understanding of how {topic} operate, including their properties and the key operations performed on them, such as {key_operations}.\n","Algorithm Type: Emphasize {algorithm_focus} within the context of {topic}. The candidate should demonstrate proficiency in implementing these algorithms and understanding their implications on the overall structure and efficiency of the {topic}.\n","Advanced Concepts: The question should also touch upon {advanced_concept} as a potential extension, assessing the candidate's knowledge of how these advanced structures maintain the efficiency of operations in the presence of skewed data.\n","Difficulty Level and Target Audience:\n","The question should be of {difficulty_level} difficulty, appropriate for candidates with {experience_range} of professional experience in software development, particularly those who have a solid understanding of data structures and algorithms.\n","Ensure that the problem is challenging enough to differentiate between candidates who have merely theoretical knowledge and those who can apply this knowledge in a practical, optimized manner.\n","The problem should be solvable within a {time_limit} interview, but it should also allow for deeper discussion on optimizations, edge cases, and alternative approaches if time permits.\n","Assessment Criteria:\n","Implementation: The candidate should be required to implement core operations of a {topic} such as {core_operations}. This implementation should be robust, efficient, and correct.\n","Algorithm Optimization: Evaluate how well the candidate can optimize these operations, particularly in scenarios where the {topic} may become unbalanced. Encourage discussion around the trade-offs involved in implementing different balancing techniques or using a self-balancing tree.\n","Complexity Analysis: Require the candidate to analyze the {complexity_analysis} of their implementation. They should be able to articulate the complexity in terms of {notation}, explaining how their implementation performs in {scenario_types} scenarios.\n","Edge Cases and Robustness: The question should explicitly require handling of edge cases such as {edge_cases}. The candidate should demonstrate an understanding of how these cases can affect the behavior and efficiency of {topic} operations.\n","Problem-Solving Approach: The candidate's approach to solving the problem should be methodical, logical, and well-structured. They should clearly explain their thought process, justify their choices, and consider alternative solutions.\n","Question Structure:\n","Part 1: Basic Implementation: Start with a task requiring the candidate to implement basic operations of a {topic}. This part should test their fundamental understanding of how {topic} work and ensure they can write correct and efficient code.\n","Part 2: Optimization Challenge: Once the basic implementation is complete, present the candidate with a challenge to optimize their {topic}. For instance, they could be asked to handle scenarios where the {topic} becomes unbalanced, discussing potential solutions like {optimization_technique}.\n","Part 3: Edge Cases and Analysis: Ask the candidate to identify and address specific edge cases. They should explain how their implementation handles cases like {specific_edge_cases} and how it affects the overall performance.\n","Part 4: Complexity Discussion: End with a discussion on complexity. The candidate should analyze the time and space complexity of their implementation, considering different scenarios and providing a clear explanation for their conclusions.\n","Detailed Solution Expectations:\n","Step-by-Step Implementation: The candidate should write code in {programming_language}, with each step clearly documented and explained. The code should be clean, efficient, and follow best practices.\n","Explanatory Commentary: Each part of the code should be accompanied by detailed comments explaining what the code is doing and why certain choices were made. This should include the rationale behind the data structures used, the logic of the algorithms, and any optimizations implemented.\n","Complexity Justification: For each operation implemented, the candidate should provide a thorough analysis of the time and space complexity. They should explain how the complexity is derived, using {notation}, and discuss how it varies under different conditions (e.g., balanced vs. unbalanced trees).\n","Edge Case Handling: The solution should be robust, with explicit handling of edge cases. The candidate should describe how they tested for these cases and the adjustments they made to ensure their code handles them correctly.\n","Optimizations and Alternatives: If applicable, the candidate should be encouraged to suggest alternative approaches or optimizations. For example, they could discuss the pros and cons of using a {advanced_concept} versus a standard {topic}, and under what circumstances one might be preferred over the other.\n","Bonus Components:\n","Advanced Tree Operations: If time allows, include a bonus question that challenges the candidate to implement more advanced operations on the {topic}, such as {advanced_operation}. This would test their ability to extend their implementation and handle more complex requirements.\n","Theoretical Discussion: Encourage a discussion on the theory behind {topic}, including their place in the broader context of data structures and algorithms. Ask the candidate to compare {topic} with other data structures like {comparison_structure_1} or {comparison_structure_2}, explaining when and why a {topic} might be preferable.\n","Real-World Application: Finally, ask the candidate to think about real-world applications of {topic}. How might a {topic} be used in a production environment? What are some potential pitfalls, and how could they be mitigated?\n","Evaluation and Scoring:\n","Correctness: Assess the correctness of the candidate's implementation. Did they correctly implement the required operations? Does their code handle all specified cases, including edge cases?\n","Efficiency: Evaluate the efficiency of the candidate's solution. Did they choose the most appropriate algorithms and data structures for the problem? How does their implementation perform in terms of time and space complexity?\n","Clarity and Communication: Consider how well the candidate communicated their thought process. Were they able to clearly explain their approach, justify their choices, and articulate the complexity of their solution?\n","Problem-Solving Skills: Finally, assess the candidate's overall problem-solving skills. Did they approach the problem in a logical and structured way? Were they able to adapt their solution to handle more complex requirements or edge cases? How well did they perform under time constraints?\n","\"\"\"\n","\n","\n","\n","print(\"Without Llumo Compression:\")\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n",")\n","print(response.choices[0].message.content)\n","print(f\"Tokens used: {response.usage.total_tokens}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"X8-LbBXAN1mF"},"source":["##Test with Llumo compression\n","###Applying Llumo compression:\n","\n","* We call compress_with_llumo() with our example prompt.\n","* The function returns multiple values, which we unpack into separate variables.\n","\n","\n","###Checking compression success:\n","\n","* We use an if statement to check if compression was successful.\n","* If successful, we print compression statistics: percentage, initial and final token counts.\n","\n","\n","###Using the compressed prompt:\n","\n","* If compression succeeded, we use the compressed prompt in our API call to GPT-3.5-turbo.\n","* We use the same message structure as before, but with the compressed prompt.\n","\n","\n","###Displaying results:\n","\n","* We print the AI's response to the compressed prompt.\n","* We print the number of tokens used with the compressed prompt.\n","\n","\n","###Handling compression failure:\n","\n","* If compression fails, we print a message indicating this.\n","* In a real application, you might want to fall back to using the original prompt in this case.\n","\n","\n","\n","This cell demonstrates the full process of compressing a prompt with Llumo and using it with the OpenAI API. By comparing the results and token usage with the previous cell, you can see the potential benefits of using Llumo compression in terms of token efficiency and cost savings."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18803,"status":"ok","timestamp":1725535428893,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"0L-PTGeybF-r","outputId":"4ab46cc3-e44e-4051-df40-beebb1ef48fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["With Llumo Compression:\n","Compression achieved: 50.25%\n","Initial tokens: 1389, Final tokens: 691\n","Interview Question: Implementing and Optimizing Binary Search Trees (BSTs) - A Deep Dive\n","\n","Part 1: Basic Task Implementation (20 minutes)\n","You are tasked with implementing a Binary Search Tree (BST) in Python. Your implementation should include the core operations of insertion, deletion, and search. You should strive for efficiency and correctness in your implementation. Handle scenarios where the BST may become unbalanced and discuss potential solutions for implementing a self-balancing tree. Additionally, consider cases such as handling duplicate keys and empty trees in your implementation for robustness and performance.\n","\n","Part 2: Complex Discussion (25 minutes)\n","After completing the basic implementation, let's move on to a deeper discussion. Explain the time and space complexity of your implementation. Consider scenarios where the BST becomes unbalanced and discuss methods to optimize the tree to maintain balance. Demonstrate an understanding of different balancing techniques and how they impact the efficiency of operations in a BST. Provide real-world examples where BSTs are utilized and discuss how the structures of BSTs can be adapted using maps or tables for specific applications.\n","\n","Detailed Explanation:\n","Step 1: Implementation\n","You should start by writing Python code to implement a Binary Search Tree. Provide detailed explanations in the comments for each operation (insertion, deletion, search) implemented. Utilize appropriate algorithms and data structures in your implementation. Consider the use of Big O notation to analyze the time and space complexity of your code.\n","\n","Step 2: Case Handling\n","Explicitly address scenarios involving duplicate keys and empty trees in your BST implementation. Describe how you handle these cases within your code and suggest improvements if needed. Discuss the advantages and drawbacks of these solutions in managing edge cases effectively.\n","\n","Step 3: Real-World Applications\n","Engage in a conversation about the practical applications of BSTs in real-world scenarios. Discuss how BST structures can be adapted and optimized for specific use cases, such as maintaining balance in the face of changing data. Encourage a discussion on advanced concepts like self-balancing trees and their implications on algorithmic efficiency.\n","\n","Assessment Criteria:\n","- Correctness: Evaluate if the candidate's code handles all cases correctly.\n","- Efficiency: Assess the time and space complexity of the candidate's implementation.\n","- Clarity: Evaluate how clearly the candidate communicates their thought process and solution.\n","- Problem-Solving Skills: Analyze the candidate's logical and methodical approach to solving the problem and adapting to complex requirements.\n","\n","This question is designed to challenge the candidate's abilities in implementing, optimizing, and analyzing algorithms in the context of Binary Search Trees. It aims to gauge their proficiency in data structures, algorithmic optimization, and problem-solving skills within a realistic timeframe for a mid-level software engineer.\n","Tokens used: 1248\n"]}],"source":["# Cell 5: Test with Llumo compression\n","\n","print(\"With Llumo Compression:\")\n","compressed_prompt, success, compression_percentage, initial_tokens, final_tokens = compress_with_llumo(prompt)\n","\n","if success:\n","    print(f\"Compression achieved: {compression_percentage:.2f}%\")\n","    print(f\"Initial tokens: {initial_tokens}, Final tokens: {final_tokens}\")\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","            {\"role\": \"user\", \"content\": compressed_prompt}\n","        ]\n","    )\n","    print(response.choices[0].message.content)\n","    print(f\"Tokens used: {response.usage.total_tokens}\")\n","else:\n","    print(\"Compression failed. Using original prompt.\")\n","    # Use the original prompt if compression fails"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"HJf2c7E7KMVT"},"source":["##Setting up the environment\n","###Importing libraries:\n","\n","* os: This module provides a way to use operating system dependent functionality, like reading environment variables.\n","* OpenAI: This is the official OpenAI Python client, used to interact with OpenAI's API.\n","* requests: A popular library for making HTTP requests in Python.\n","* json: Used for parsing JSON data, which is common in API responses.\n","* logging: Provides a flexible framework for generating log messages in Python.\n","* getpass: Allows secure password prompts where the input is not displayed on the screen.\n","\n","\n","###Setting up logging:\n","\n","* We use `logging.basicConfig()` to configure the logging system. The `level=logging.INFO` argument sets the threshold for logging messages to INFO level and above.\n","* We create a logger object named logger that we'll use throughout our script to log important information and errors.\n","\n","\n","\n","This setup ensures we have all necessary tools to interact with APIs, handle data, and track any issues that might occur during execution."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5580,"status":"ok","timestamp":1725334613853,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"JI7kRgEWNSc-","outputId":"55154d15-f63e-46c7-9106-ea2a55e91291"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n","Libraries imported and logging set up successfully.\n"]}],"source":["!pip install openai\n","import os\n","from openai import OpenAI\n","import requests\n","import json\n","import logging\n","from getpass import getpass\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"Libraries imported and logging set up successfully.\")"]},{"cell_type":"markdown","metadata":{"id":"XNoUu5e8K4-u"},"source":["##Secure API key handling\n","###Secure API key input:\n","\n","* We use `getpass()` to prompt the user for their API keys. This function hides the input, making it more secure than using regular input().\n","* This approach is safer than hardcoding API keys in your script, which could accidentally be shared or exposed.\n","\n","\n","###Setting environment variables:\n","\n","* We use `os.environ` to set environment variables for both API keys.\n","* Environment variables are a secure way to store sensitive information, as they're not part of your code and are only accessible within the current process.\n","\n","\n","###Initializing the OpenAI client:\n","\n","* We create an instance of the OpenAI client using the API key we just set.\n","* Using `os.getenv(\"OPENAI_API_KEY\")` retrieves the API key from the environment variables.\n","\n","\n","\n","This method ensures that your API keys are handled securely and are readily available for use in your script."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zO7mU9nHLstm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725334637570,"user_tz":-330,"elapsed":16042,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"}},"outputId":"03aa6908-f873-4de5-babd-4bdcb4ebe5b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your OpenAI API key: ··········\n","Enter your Llumo API key: ··········\n","API keys securely set and OpenAI client initialized.\n"]}],"source":["# Cell 2: Secure API key handling\n","\n","# Securely input API keys\n","openai_api_key = getpass(\"Enter your OpenAI API key: \")\n","llumo_api_key = getpass(\"Enter your Llumo API key: \")\n","\n","# Set environment variables\n","os.environ['OPENAI_API_KEY'] = openai_api_key\n","os.environ['LLUMO_API_KEY'] = llumo_api_key\n","\n","# Initialize OpenAI client\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n","\n","print(\"API keys securely set and OpenAI client initialized.\")"]},{"cell_type":"markdown","metadata":{"id":"PfSNDHSVLv6q"},"source":["##Define Llumo compression function\n","###Function definition:\n","\n","* We define a function `compress_with_llumo` that takes a text input and an optional topic.\n","\n","\n","###API setup:\n","\n","* We retrieve the Llumo API key from environment variables.\n","* We set the API endpoint and prepare headers for the HTTP request.\n","\n","\n","###Payload preparation:\n","\n","* We create a payload dictionary with the input text.\n","* If a topic is provided, we add it to the payload.\n","\n","\n","###API request:\n","\n","* We use `requests.post()` to send a POST request to the Llumo API.\n","`response.raise_for_status()` will raise an exception for HTTP errors.\n","\n","\n","###Response parsing:\n","\n","* We parse the JSON response and extract the compressed text and token counts.\n","* We calculate the compression percentage.\n","\n","\n","###Error handling:\n","\n","* We use a try-except block to catch potential errors:\n","\n"," * JSON decoding errors\n"," * Request exceptions\n"," * Unexpected response structure\n","\n","\n","* If an error occurs, we log it and return the original text with failure indicators.\n","\n","\n","### Return values:\n","\n","* The function returns a tuple containing:\n","\n"," * Compressed text (or original if compression failed)\n"," * Success boolean\n"," * Compression percentage\n"," * Initial token count\n"," * Final token count\n","\n","\n","\n","\n","\n","This function encapsulates the entire process of interacting with the Llumo API for text compression, including error handling and result processing."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1725333382204,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"tCoNUERsLuRS"},"outputs":[],"source":["def compress_with_llumo(text):\n","    # Retrieve the Llumo API key from environment variables\n","    LLUMO_API_KEY = os.getenv('LLUMO_API_KEY')\n","\n","    # Define the Llumo API endpoint for text compression\n","    LLUMO_ENDPOINT = \"https://app.llumo.ai/api/compress\"\n","\n","    # Set the headers for the API request\n","    headers = {\n","        \"Content-Type\": \"application/json\",  # Specify the content type as JSON\n","        \"Authorization\": f\"Bearer {LLUMO_API_KEY}\"  # Authorization header with the API key\n","    }\n","\n","    # Create the payload for the API request with the provided text\n","    payload = {\"prompt\": text}\n","\n","    try:\n","        # Make a POST request to the Llumo API with the payload and headers\n","        response = requests.post(LLUMO_ENDPOINT, json=payload, headers=headers)\n","        response.raise_for_status()\n","\n","        # Parse the JSON response from the API\n","        result = response.json()\n","        data = json.loads(result['data']['data'])\n","\n","        # Extract compressed text and token information\n","        compressed_text = data.get('compressedPrompt', text)\n","        initial_tokens = data.get('initialTokens', 0)\n","        final_tokens = data.get('finalTokens', 0)\n","\n","        # Calculate the compression percentage\n","        compression_percentage = ((initial_tokens - final_tokens) / initial_tokens) * 100 if initial_tokens else 0\n","\n","        # Return the compressed text, success flag, compression percentage, and token counts\n","        return compressed_text, True, compression_percentage, initial_tokens, final_tokens\n","    except Exception as e:\n","        print(f\"Error compressing text: {str(e)}\")\n","        return text, False, 0, 0, 0\n"]},{"cell_type":"markdown","metadata":{"id":"o59T0PevM8no"},"source":["##Define example prompt and test without compression\n","###Defining the prompt:\n","\n","* We create a detailed prompt about photosynthesis. This serves as our example text for compression.\n","\n","\n","###Testing without compression:\n","\n","* We use the OpenAI client to send a request to the GPT-3.5-turbo model.\n","* The messages parameter follows the chat format:\n","\n"," * A system message sets the AI's role.\n"," * A user message contains our prompt.\n","\n","\n","\n","\n","###Displaying results:\n","\n","* We print the AI's response to the prompt.\n","* We also print the total number of tokens used, which is important for understanding API usage and costs.\n","\n","This cell demonstrates how the API would typically be used without any compression, providing a baseline for comparison.\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4626,"status":"ok","timestamp":1725334719814,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"nv0xHxrSNyKl","outputId":"cec2de69-02f2-48c1-ef54-122ba60330f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Without Llumo Compression:\n","**How does Flexicab help Rickshaw drivers increase their earnings?**\n","\n","Flexicab empowers Rickshaw drivers to boost their earnings through various key features and benefits tailored to enhance their efficiency and profitability:\n","\n","1. **Route Optimization**: By utilizing real-time traffic data and historical ride patterns, Flexicab suggests the most efficient routes for each trip. This minimizes travel time and fuel consumption, enabling drivers to complete more rides within a given timeframe and increase their daily earnings.\n","\n","2. **Fare Calculation & Management**: The platform automatically calculates fares based on distance, time, and other factors, ensuring transparency for both drivers and passengers. This accurate fare calculation system eliminates any uncertainty around pricing, allowing drivers to maximize their earning potential on each trip.\n","\n","3. **Customer Management**: Flexicab provides drivers with tools to manage their customer base, track ride history, and offer personalized promotions. By building customer loyalty and attracting repeat clients, drivers can increase their overall revenue stream through a steady flow of customers.\n","\n","4. **Data Analytics & Insights**: The platform offers valuable insights into driver performance, customer behavior, and market trends. By leveraging this data, drivers can optimize their pricing strategies, identify high-demand areas, and make informed decisions to tap into lucrative opportunities, ultimately increasing their earnings.\n","\n","In summary, Flexicab equips Rickshaw drivers with the tools and resources to work smarter, not harder. By optimizing routes, ensuring fair fares, enhancing customer relationships, and leveraging data-driven insights, Flexicab paves the way for drivers to enhance their earnings significantly in today's competitive urban landscape.\n","\n","If you have any more questions about how Flexicab can benefit Rickshaw drivers, feel free to ask!\n","Tokens used: 988\n","\n"]}],"source":["# Cell 4: Define example prompt and test without compression\n","\n","# Example prompt\n","prompt = \"\"\"\n","Context: Flexicab: The Smart Rickshaw Management PlatformFlexicab is a revolutionary SaaS platform designed specifically for Rickshaw drivers and owners in bustling urban environments. It addresses the unique challenges faced by this vital mode of transportation, empowering them with modern tools to optimize their operations and increase their earnings.**Key Features:*** **Route Optimization:** Flexicab leverages real-time traffic data and historical ride patterns to suggest the most efficient routes for each trip, minimizing travel time and fuel consumption. This feature helps drivers maximize their earnings by completing more rides within a given timeframe.* **Fare Calculation & Management:** Flexicab automatically calculates fares based on distance, time, and other factors, ensuring transparency and accuracy for both drivers and passengers. It also integrates with popular payment gateways, allowing for seamless digital transactions and reducing the risk of cash handling.* **Customer Management:** Flexicab provides a platform for drivers to manage their customer base, track ride history, and build loyalty through personalized offers and promotions. This helps drivers attract repeat customers and increase their overall revenue.* **Fleet Management:** For Rickshaw owners with multiple vehicles, Flexicab offers a comprehensive fleet management system. This includes vehicle tracking, maintenance scheduling, driver performance monitoring, and real-time communication tools to ensure efficient operations and safety.* **Data Analytics & Insights:** Flexicab provides valuable insights into driver performance, customer behavior, and market trends. This data can be used to optimize pricing strategies, identify high-demand areas, and make informed business decisions.**Benefits:*** **Increased Earnings:** By optimizing routes, managing fares effectively, and attracting more customers, Flexicab helps drivers significantly increase their earnings.* **Improved Efficiency:** Flexicab streamlines operations, reducing wasted time and effort, allowing drivers to focus on providing excellent service.* **Enhanced Safety:** The platform's features, such as vehicle tracking and driver performance monitoring, contribute to a safer environment for both drivers and passengers.* **Digital Transformation:** Flexicab empowers Rickshaw drivers and owners to embrace digital technology, making their businesses more modern and competitive.**Target Audience:*** Rickshaw drivers* Rickshaw owners* Transportation companies operating Rickshaws* City governments and transportation authorities looking to improve urban mobility and support sustainable transportation options.**Flexicab is more than just a platform; it's a comprehensive solution that empowers Rickshaw drivers and owners to thrive in the modern urban landscape.\n","Query: How does Flexicab help Rickshaw drivers increase their earnings?\n","Instructions:You are a helpful and informative chatbot designed to answer questions about Flexicab, a SaaS platform for Rickshaw drivers and owners. Use the provided context to answer the user's query in a comprehensive and engaging manner. **Response Format:*** Begin your response with a clear and concise answer to the user's question.* Provide additional details and explanations to support your answer, drawing from the provided context.* Use bullet points or numbered lists to organize information and make it easier to read.* If applicable, include specific examples or scenarios to illustrate your points.* End your response with a friendly and helpful tone, encouraging further interaction.**\n","\"\"\"\n","\n","\n","\n","print(\"Without Llumo Compression:\")\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n",")\n","print(response.choices[0].message.content)\n","print(f\"Tokens used: {response.usage.total_tokens}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"X8-LbBXAN1mF"},"source":["##Test with Llumo compression\n","###Applying Llumo compression:\n","\n","* We call compress_with_llumo() with our example prompt.\n","* The function returns multiple values, which we unpack into separate variables.\n","\n","\n","###Checking compression success:\n","\n","* We use an if statement to check if compression was successful.\n","* If successful, we print compression statistics: percentage, initial and final token counts.\n","\n","\n","###Using the compressed prompt:\n","\n","* If compression succeeded, we use the compressed prompt in our API call to GPT-3.5-turbo.\n","* We use the same message structure as before, but with the compressed prompt.\n","\n","\n","###Displaying results:\n","\n","* We print the AI's response to the compressed prompt.\n","* We print the number of tokens used with the compressed prompt.\n","\n","\n","###Handling compression failure:\n","\n","* If compression fails, we print a message indicating this.\n","* In a real application, you might want to fall back to using the original prompt in this case.\n","\n","\n","\n","This cell demonstrates the full process of compressing a prompt with Llumo and using it with the OpenAI API. By comparing the results and token usage with the previous cell, you can see the potential benefits of using Llumo compression in terms of token efficiency and cost savings."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9768,"status":"ok","timestamp":1725334750143,"user":{"displayName":"Jatin Agarwal","userId":"14406162079289589360"},"user_tz":-330},"id":"0L-PTGeybF-r","outputId":"fab70593-ec95-43c7-b360-10965bcd161f"},"outputs":[{"output_type":"stream","name":"stdout","text":["With Llumo Compression:\n","Compression achieved: 58.64%\n","Initial tokens: 631, Final tokens: 261\n","To help Rickshaw drivers increase their earnings, Flexicab provides a range of features and benefits that optimize their operations and enhance their overall performance. Here are some ways in which Flexicab helps drivers improve their earnings:\n","\n","1. **Route Optimization**: Flexicab helps drivers by optimizing their routes, suggesting the most efficient paths to maximize the number of rides they can complete in a specific time frame. This ensures that drivers can cater to more customers and earn more during their working hours.\n","\n","2. **Enhanced Communication and Data Analysis**: By providing real-time communication tools and insights into driver and industry trends, Flexicab enables drivers to make informed decisions. This helps them identify high-demand areas and adjust their services accordingly to attract more customers.\n","\n","3. **Seamless Payment Transactions**: Flexicab facilitates seamless payment transactions, allowing drivers to receive their earnings promptly and efficiently after completing a trip. This feature eliminates the hassle of cash transactions and ensures that drivers can focus on providing excellent service rather than handling payments.\n","\n","4. **Customer Loyalty and Personalized Offers**: Flexicab enables drivers to build customer loyalty through personalized offers and incentives. By rewarding repeat customers and providing tailored experiences, drivers can attract more riders and increase their revenue over time.\n","\n","5. **Embracing Technology**: Flexicab empowers Rickshaw drivers to embrace technology and leverage innovative tools to improve their services and efficiency. By adopting technology-driven solutions, drivers can enhance their visibility, attract more customers, and ultimately boost their earnings.\n","\n","In summary, Flexicab provides a comprehensive platform that equips Rickshaw drivers with the tools and resources they need to enhance their earnings through route optimization, data analysis, seamless transactions, customer loyalty programs, and technology integration. By utilizing these features effectively, drivers can maximize their revenue potential and grow their business successfully.\n","\n","If you have any further questions or need more details on how Flexicab can benefit Rickshaw drivers, feel free to ask!\n","Tokens used: 668\n"]}],"source":["# Cell 5: Test with Llumo compression\n","\n","print(\"With Llumo Compression:\")\n","compressed_prompt, success, compression_percentage, initial_tokens, final_tokens = compress_with_llumo(prompt)\n","\n","if success:\n","    print(f\"Compression achieved: {compression_percentage:.2f}%\")\n","    print(f\"Initial tokens: {initial_tokens}, Final tokens: {final_tokens}\")\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","            {\"role\": \"user\", \"content\": compressed_prompt}\n","        ]\n","    )\n","    print(response.choices[0].message.content)\n","    print(f\"Tokens used: {response.usage.total_tokens}\")\n","else:\n","    print(\"Compression failed. Using original prompt.\")\n","    # Use the original prompt if compression fails"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}